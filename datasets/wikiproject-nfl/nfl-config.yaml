## Configuration file for creating a snapshot of WikiProject China
name: "WikiProject National Football League"

## Full category name (without namespace) for each of the four
## importance categories we are concerned with:
importance categories: {
    Top: "Top-importance National Football League articles",
    High: "High-importance National Football League articles",
    Mid: "Mid-importance National Football League articles",
    Low: "Low-importance National Football League articles"
    }

## Additional categories of articles, these are used when counting
## inlinks from within the project.
support categories:
 - "NA-importance National Football League articles"
 - "Unknown-importance National Football League articles"

## Path to the snapshot dataset TSV for this project.
snapshot file: wikiproject-nfl-snapshot-20170616.tsv

## Path to the TSV containing articles identified as disambiguation pages
disambiguation file: wikiproject-nfl-disambiguations-20170616.tsv

## Path to the TSV dataset with inlink counts, pageviews, and Wikidata items
dataset: wikiproject-nfl-dataset-20170616.tsv

## Path to the TSV clickstream dataset with clicks, referrer counts, etc
clickstream file: wikiproject-nfl-clickstream-20170616.tsv

## Path to the GEXF file with the Wikidata network
wikidata network: wikiproject-nfl-network-20170616.gexf

## Path to the wikitable with articles that might need rerating
prediction table: wikiproject-nfl-predictions-20170616.txt

## Path to the dataset of articles that will be sidechained
## WikiProject NFL currently has no such articles, so this file is empty.
sidechain file: wikiproject-nfl-sidechain-20170616.tsv

## Predictive columns
predictors:
 - "rank_views_perc"
 - "rank_links_perc"
 - "prop_proj_inlinks"
 - "prop_from_art"
 - "prop_act_inlinks"

## Label column
labels: "importance_rating"

## Number of articles to use for training and test sets when training
## and evaluating the model:
test set size: 50
training set size: 230

## Configuration for SMOTE, which class should be SMOTEd, and how many
## times larger the SMOTEd training set should be:
SMOTE evaluation: 1
SMOTE class: "Top"
SMOTE factor: 2

## Note that in this case we're limited by the number of High-importance
## articles (566), which is why our SMOTE-factor is 2.

## Number of articles to use for training the final model, and whether
## to use SMOTE for oversampling there as well (with same settings as above):
final training size: 255
SMOTE final: 1

## Model parameters, ref http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html
model parameters: {
    'n_estimators' : 500,
    'learning_rate': 0.05,
    'max_depth': 7,
    'min_samples_leaf': 8,
    'random_state': 42
}

## Where to write out the trained model
model file: wikiproject-nfl.gbm.model
